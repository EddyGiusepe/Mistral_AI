{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e434db5a",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"gree\">Mistral AI Agents API Tutorial</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db75300",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264eb466",
   "metadata": {},
   "source": [
    "Links de estudo:\n",
    "\n",
    "* [Obtenha a sua chave de API do Mistral AI](https://console.mistral.ai/api-keys)\n",
    "\n",
    "* [DataCamp - Mistral AI](https://www.youtube.com/watch?v=VkqYmwIIeOg)\n",
    "\n",
    "* [Mistral AI Cookbook](https://github.com/mistralai/cookbook/tree/main)\n",
    "\n",
    "* [Visão geral de modelos](https://docs.mistral.ai/getting-started/models/models_overview/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a51095",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Começando</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d504c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import os\n",
    "\n",
    "# Alternativamente, você pode usar variáveis de ambiente\n",
    "MISTRALAI_API_KEY = os.environ.get(\"MISTRALAI_API_KEY\") \n",
    "\n",
    "client = Mistral(api_key=MISTRALAI_API_KEY)\n",
    "\n",
    "ml_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-2505\",\n",
    "    name=\"ml-agent\",\n",
    "    description=\"Asistente de Machine learning\",\n",
    "    instructions=\"Você é um especialista em Machine learning. Dá conselhos práticos e ações.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6370ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created: ag_019818e32a1c73d88638d1a73a709ff8\n",
      "\n",
      "\n",
      "Agent name: ml-agent\n",
      "\n",
      "\n",
      "Agent description: Asistente de Machine learning\n",
      "\n",
      "\n",
      "Agent instructions: Você é um especialista em Machine learning. Dá conselhos práticos e ações.\n",
      "\n",
      "\n",
      "Agent model: mistral-medium-2505\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent created: {ml_agent.id}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent name: {ml_agent.name}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent description: {ml_agent.description}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent instructions: {ml_agent.instructions}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent model: {ml_agent.model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63d9c2",
   "metadata": {},
   "source": [
    "* ``mistral-medium`` é um modelo pago com um equilíbrio entre desempenho e custo\n",
    "* ``name`` deve ser único para manter conversas separadas\n",
    "* ``instructions`` é o prompt do sistema que guia o comportamento do agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be5e4f",
   "metadata": {},
   "source": [
    "Os Agents API usam IDs de agentes para diferenciar um agente de outro\n",
    "\n",
    "\n",
    "<font color=\"gree\">Iniciando uma conversa</font>\n",
    "\n",
    "* Para começar a fazer perguntas, use o comando ``start``\n",
    "* Deve passar o ``ID`` de agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93974a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.conversations.start(\n",
    "    agent_id=ml_agent.id,\n",
    "    inputs=\"\"\"Devo usar Random Forest ou XGBoost para um dataset de \n",
    "              5000 amostras? Responda em uma sentença apenas.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d8ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistralai.models.conversationresponse.ConversationResponse"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b105e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageOutputEntry(content='Para um dataset de 5000 amostras, XGBoost geralmente oferece melhor desempenho e eficiência.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 15, 6, 14, 383662, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 15, 6, 14, 708149, tzinfo=TzInfo(UTC)), id='msg_019818ebf7ef72b79a5092bf66a696eb', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ddeb2",
   "metadata": {},
   "source": [
    "* O array de saídas (``outputs``) conterá outros objetos de mensagem como chamadas de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39607d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dataset de 5000 amostras, XGBoost geralmente oferece melhor desempenho e eficiência.\n"
     ]
    }
   ],
   "source": [
    "print(response.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decac5d1",
   "metadata": {},
   "source": [
    "Isto é um workflow básico para criar agentes e iniciar conversas com eles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad74e4",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Mergulho profundo na API de agentes Mistral</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b4fe4",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``1.`` Criando agentes eficazes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a78071",
   "metadata": {},
   "source": [
    "* O desempenho do agente é determinado por:\n",
    "\n",
    "1. Escolha do modelo\n",
    "2. Prompt do sistema\n",
    "3. Parâmetros de conclusão (`Completion`)\n",
    "\n",
    "* Escolha o modelo certo na página de [visão geral de modelos](https://docs.mistral.ai/getting-started/models/models_overview/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data agent: ag_01981910206d75709f9cf966b4e184f3\n"
     ]
    }
   ],
   "source": [
    "# Agentes especializados com diferentes configurações:\n",
    "data_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-latest\",\n",
    "    name=\"data-expert\",\n",
    "    description=\"Especialista em pré-processamento de dados\",\n",
    "    instructions=\"Especialista em limpeza de dados e engenharia de recursos (feature engineering)\",\n",
    "    completion_args={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "print(f\"Data agent: {data_agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb197031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='mistral-medium-latest' name='data-expert' id='ag_01981910206d75709f9cf966b4e184f3' version=0 created_at=datetime.datetime(2025, 7, 17, 15, 45, 44, 49338, tzinfo=TzInfo(UTC)) updated_at=datetime.datetime(2025, 7, 17, 15, 45, 44, 49340, tzinfo=TzInfo(UTC)) instructions='Especialista em limpeza de dados e engenharia de recursos (feature engineering)' tools=[] completion_args=CompletionArgs(stop=None, presence_penalty=None, frequency_penalty=None, temperature=0.0, top_p=None, max_tokens=None, random_seed=None, prediction=None, response_format=None, tool_choice='auto') description='Especialista em pré-processamento de dados' handoffs=None object='agent'\n"
     ]
    }
   ],
   "source": [
    "print(data_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499bc68",
   "metadata": {},
   "source": [
    "* Use modelos premium (pagos) para cenários de alto impacto que exigem forte ``raciocínio/codificação``. Boas opções são:\n",
    "    * ``Codestral 2`` para codificação\n",
    "    * ``Magistral medium`` para raciocínio\n",
    "* Faça o ``prompt do sistema`` o mais detalhado possível - dedique a maior parte do seu tempo aqui\n",
    "* A ``temperatura`` controla a aleatoriedade da próxima palavra\n",
    "    * ``0.1-0.5`` para precisão factual (codificação, documentos técnicos)\n",
    "    * ``0.5-1`` para criatividade (brainstorming (gerar ideias), menos robótico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c152cbd7",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``2.``Gerenciando conversas com um agente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c84418",
   "metadata": {},
   "source": [
    "* A maioria dos frameworks de construção de agentes não possui memória embutida\n",
    "* Os casos de uso em produção são diferentes\n",
    "* O ``Mistral`` vem com memória embutida e gerenciamento de conversas\n",
    "\n",
    "<font color=\"red\">``I.`` Iniciando uma nova conversa</font>\n",
    "\n",
    "* O comando ``start`` sempre espera um novo ID de agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d10c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui estão três melhores práticas para codificar variáveis categóricas em aprendizado de máquina:\n",
      "\n",
      "1. **One-Hot Encoding**:\n",
      "   - **Descrição**: Transforma cada categoria em uma coluna binária (0 ou 1). Cada coluna representa uma categoria única.\n",
      "   - **Quando usar**: Quando as categorias não têm uma ordem intrínseca (por exemplo, cores, países).\n",
      "   - **Exemplo**: Se você tem uma variável \"Cor\" com categorias \"Vermelho\", \"Azul\" e \"Verde\", o One-Hot Encoding criará três colunas binárias, cada uma representando uma dessas cores.\n",
      "\n",
      "2. **Label Encoding**:\n",
      "   - **Descrição**: Atribui um número inteiro único a cada categoria.\n",
      "   - **Quando usar**: Quando as categorias têm uma ordem intrínseca (por exemplo, níveis de educação: \"Ensino Fundamental\", \"Ensino Médio\", \"Ensino Superior\").\n",
      "   - **Exemplo**: Se você tem uma variável \"Nível de Educação\" com categorias \"Ensino Fundamental\", \"Ensino Médio\" e \"Ensino Superior\", o Label Encoding pode atribuir 0, 1 e 2, respectivamente.\n",
      "\n",
      "3. **Embedding**:\n",
      "   - **Descrição**: Usa redes neurais para transformar categorias em vetores de números reais em um espaço de menor dimensão.\n",
      "   - **Quando usar**: Quando você tem um grande número de categorias e deseja capturar relações complexas entre elas, geralmente em modelos de deep learning.\n",
      "   - **Exemplo**: Em processamento de linguagem natural, palavras são frequentemente transformadas em embeddings para capturar semelhanças semânticas.\n",
      "\n",
      "Essas técnicas ajudam a transformar variáveis categóricas em formatos que podem ser processados por algoritmos de aprendizado de máquina.\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.conversations.start(\n",
    "    agent_id=ml_agent.id,\n",
    "    inputs=\"\"\"Quais são as melhores práticas para codificar variáveis \n",
    "              categóricas em aprendizado de máquina? Liste três.\"\"\",\n",
    ")\n",
    "\n",
    "print(response.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729393d",
   "metadata": {},
   "source": [
    "* Todos os objetos de ``response`` de conversação também têm um ``ID``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab120234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_01981929efd671908fe477e0bc9cf15c\n"
     ]
    }
   ],
   "source": [
    "print(response.conversation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76259a0",
   "metadata": {},
   "source": [
    "<font color=\"red\">``II.`` Continuando uma conversa existente</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ff3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sua primeira pergunta foi: \"Quais são as melhores práticas para codificar variáveis categóricas em aprendizado de máquina? Liste três.\"\n"
     ]
    }
   ],
   "source": [
    "# Continuar uma conversa existente:\n",
    "follow_up = client.beta.conversations.append(\n",
    "    conversation_id=response.conversation_id,\n",
    "    inputs=\"Qual foi a minha primeira pergunta?\",\n",
    ")\n",
    "\n",
    "print(follow_up.outputs[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974d6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você perguntou sobre as melhores práticas para codificar variáveis categóricas em aprendizado de máquina. Eu listei três técnicas: One-Hot Encoding, Label Encoding e Embedding. Em seguida, você perguntou qual foi a sua primeira pergunta.\n"
     ]
    }
   ],
   "source": [
    "follow_up = client.beta.conversations.append(\n",
    "    conversation_id=response.conversation_id,\n",
    "    inputs=\"Resuma toda a conversa em 3 frases.\",\n",
    ")\n",
    "\n",
    "print(follow_up.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7257a4",
   "metadata": {},
   "source": [
    "<font color=\"red\">``III.`` Listando todas as conversas</font>\n",
    "\n",
    "* Para gerenciamento interno, você pode ver todas as conversas dos agentes rapidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e76a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_list = client.beta.conversations.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c217470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "012b96e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv_01981929efd671908fe477e0bc9cf15c'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_list[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f7297e",
   "metadata": {},
   "source": [
    "* As conversas mais recentes vêm primeiro nesta lista.\n",
    "* Você pode obter o histórico completo de mensagens com ``get_messages``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a4b6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageInputEntry(role='user', content='Quais são as melhores práticas para codificar variáveis \\n              categóricas em aprendizado de máquina? Liste três.', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 16, 13, 55, 541356, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_01981929efd5774395e0ea813cc7f090', prefix=False),\n",
       " MessageOutputEntry(content='Aqui estão três melhores práticas para codificar variáveis categóricas em aprendizado de máquina:\\n\\n1. **One-Hot Encoding**:\\n   - **Descrição**: Transforma cada categoria em uma coluna binária (0 ou 1). Cada coluna representa uma categoria única.\\n   - **Quando usar**: Quando as categorias não têm uma ordem intrínseca (por exemplo, cores, países).\\n   - **Exemplo**: Se você tem uma variável \"Cor\" com categorias \"Vermelho\", \"Azul\" e \"Verde\", o One-Hot Encoding criará três colunas binárias, cada uma representando uma dessas cores.\\n\\n2. **Label Encoding**:\\n   - **Descrição**: Atribui um número inteiro único a cada categoria.\\n   - **Quando usar**: Quando as categorias têm uma ordem intrínseca (por exemplo, níveis de educação: \"Ensino Fundamental\", \"Ensino Médio\", \"Ensino Superior\").\\n   - **Exemplo**: Se você tem uma variável \"Nível de Educação\" com categorias \"Ensino Fundamental\", \"Ensino Médio\" e \"Ensino Superior\", o Label Encoding pode atribuir 0, 1 e 2, respectivamente.\\n\\n3. **Embedding**:\\n   - **Descrição**: Usa redes neurais para transformar categorias em vetores de números reais em um espaço de menor dimensão.\\n   - **Quando usar**: Quando você tem um grande número de categorias e deseja capturar relações complexas entre elas, geralmente em modelos de deep learning.\\n   - **Exemplo**: Em processamento de linguagem natural, palavras são frequentemente transformadas em embeddings para capturar semelhanças semânticas.\\n\\nEssas técnicas ajudam a transformar variáveis categóricas em formatos que podem ser processados por algoritmos de aprendizado de máquina.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 16, 13, 55, 671813, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_01981929f0577332b4851a543ecc9174', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant'),\n",
       " MessageInputEntry(role='user', content='Qual foi a minha primeira pergunta?', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 17, 59, 40, 524933, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198ac0ec749c9b5943bd43a3b82f', prefix=False),\n",
       " MessageOutputEntry(content='Sua primeira pergunta foi: \"Quais são as melhores práticas para codificar variáveis categóricas em aprendizado de máquina? Liste três.\"', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 17, 59, 40, 723863, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198ac1b37641a4ef7d318a2bbfec', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant'),\n",
       " MessageInputEntry(role='user', content='Resuma toda a conversa em 3 frases.', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 18, 0, 24, 348626, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198b6c1c739795074bdb6ec9b4d3', prefix=False),\n",
       " MessageOutputEntry(content='Você perguntou sobre as melhores práticas para codificar variáveis categóricas em aprendizado de máquina. Eu listei três técnicas: One-Hot Encoding, Label Encoding e Embedding. Em seguida, você perguntou qual foi a sua primeira pergunta.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 18, 0, 24, 551025, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198b6ce6716c8421d1ba70e45087', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = client.beta.conversations.get_messages(conversation_id=conversations_list[0].id)\n",
    "\n",
    "conversation.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b068aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversation.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60074c0d",
   "metadata": {},
   "source": [
    "* Importante ao construir aplicativos de chat (bate-papo) com histórico de mensagens\n",
    "* Veja outros [métodos de gerenciamento de conversa](https://docs.mistral.ai/agents/agents_basics/#conversations) na documentação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d15415",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``3.`` Respostas de streaming para facilidade de uso</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c38b0",
   "metadata": {},
   "source": [
    "* Os agentes devem ser amigáveis.\n",
    "* Transmita respostas sem fazê-los esperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbc548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
