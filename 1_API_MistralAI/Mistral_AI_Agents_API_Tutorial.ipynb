{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e434db5a",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"gree\">Mistral AI Agents API Tutorial</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db75300",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264eb466",
   "metadata": {},
   "source": [
    "Links de estudo:\n",
    "\n",
    "* [Obtenha a sua chave de API do Mistral AI](https://console.mistral.ai/api-keys)\n",
    "\n",
    "* [DataCamp - Mistral AI](https://www.youtube.com/watch?v=VkqYmwIIeOg)\n",
    "\n",
    "* [Mistral AI Cookbook](https://github.com/mistralai/cookbook/tree/main)\n",
    "\n",
    "* [Visão geral de modelos](https://docs.mistral.ai/getting-started/models/models_overview/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a51095",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Começando</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d504c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import os\n",
    "\n",
    "# Alternativamente, você pode usar variáveis de ambiente\n",
    "MISTRALAI_API_KEY = os.environ.get(\"MISTRALAI_API_KEY\") \n",
    "\n",
    "client = Mistral(api_key=MISTRALAI_API_KEY)\n",
    "\n",
    "ml_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-2505\",\n",
    "    name=\"ml-agent\",\n",
    "    description=\"Asistente de Machine learning\",\n",
    "    instructions=\"Você é um especialista em Machine learning. Dá conselhos práticos e ações.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6370ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created: ag_019818e32a1c73d88638d1a73a709ff8\n",
      "\n",
      "\n",
      "Agent name: ml-agent\n",
      "\n",
      "\n",
      "Agent description: Asistente de Machine learning\n",
      "\n",
      "\n",
      "Agent instructions: Você é um especialista em Machine learning. Dá conselhos práticos e ações.\n",
      "\n",
      "\n",
      "Agent model: mistral-medium-2505\n"
     ]
    }
   ],
   "source": [
    "print(f\"Agent created: {ml_agent.id}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent name: {ml_agent.name}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent description: {ml_agent.description}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent instructions: {ml_agent.instructions}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Agent model: {ml_agent.model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63d9c2",
   "metadata": {},
   "source": [
    "* ``mistral-medium`` é um modelo pago com um equilíbrio entre desempenho e custo\n",
    "* ``name`` deve ser único para manter conversas separadas\n",
    "* ``instructions`` é o prompt do sistema que guia o comportamento do agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be5e4f",
   "metadata": {},
   "source": [
    "Os Agents API usam IDs de agentes para diferenciar um agente de outro\n",
    "\n",
    "\n",
    "<font color=\"gree\">Iniciando uma conversa</font>\n",
    "\n",
    "* Para começar a fazer perguntas, use o comando ``start``\n",
    "* Deve passar o ``ID`` de agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93974a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.conversations.start(\n",
    "    agent_id=ml_agent.id,\n",
    "    inputs=\"\"\"Devo usar Random Forest ou XGBoost para um dataset de \n",
    "              5000 amostras? Responda em uma sentença apenas.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d8ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistralai.models.conversationresponse.ConversationResponse"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b105e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageOutputEntry(content='Para um dataset de 5000 amostras, XGBoost geralmente oferece melhor desempenho e eficiência.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 15, 6, 14, 383662, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 15, 6, 14, 708149, tzinfo=TzInfo(UTC)), id='msg_019818ebf7ef72b79a5092bf66a696eb', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ddeb2",
   "metadata": {},
   "source": [
    "* O array de saídas (``outputs``) conterá outros objetos de mensagem como chamadas de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39607d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dataset de 5000 amostras, XGBoost geralmente oferece melhor desempenho e eficiência.\n"
     ]
    }
   ],
   "source": [
    "print(response.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decac5d1",
   "metadata": {},
   "source": [
    "Isto é um workflow básico para criar agentes e iniciar conversas com eles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad74e4",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Mergulho profundo na API de agentes Mistral</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b4fe4",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``1.`` Criando agentes eficazes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a78071",
   "metadata": {},
   "source": [
    "* O desempenho do agente é determinado por:\n",
    "\n",
    "1. Escolha do modelo\n",
    "2. Prompt do sistema\n",
    "3. Parâmetros de conclusão (`Completion`)\n",
    "\n",
    "* Escolha o modelo certo na página de [visão geral de modelos](https://docs.mistral.ai/getting-started/models/models_overview/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data agent: ag_01981910206d75709f9cf966b4e184f3\n"
     ]
    }
   ],
   "source": [
    "# Agentes especializados com diferentes configurações:\n",
    "data_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-latest\",\n",
    "    name=\"data-expert\",\n",
    "    description=\"Especialista em pré-processamento de dados\",\n",
    "    instructions=\"Especialista em limpeza de dados e engenharia de recursos (feature engineering)\",\n",
    "    completion_args={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "print(f\"Data agent: {data_agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb197031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='mistral-medium-latest' name='data-expert' id='ag_01981910206d75709f9cf966b4e184f3' version=0 created_at=datetime.datetime(2025, 7, 17, 15, 45, 44, 49338, tzinfo=TzInfo(UTC)) updated_at=datetime.datetime(2025, 7, 17, 15, 45, 44, 49340, tzinfo=TzInfo(UTC)) instructions='Especialista em limpeza de dados e engenharia de recursos (feature engineering)' tools=[] completion_args=CompletionArgs(stop=None, presence_penalty=None, frequency_penalty=None, temperature=0.0, top_p=None, max_tokens=None, random_seed=None, prediction=None, response_format=None, tool_choice='auto') description='Especialista em pré-processamento de dados' handoffs=None object='agent'\n"
     ]
    }
   ],
   "source": [
    "print(data_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499bc68",
   "metadata": {},
   "source": [
    "* Use modelos premium (pagos) para cenários de alto impacto que exigem forte ``raciocínio/codificação``. Boas opções são:\n",
    "    * ``Codestral 2`` para codificação\n",
    "    * ``Magistral medium`` para raciocínio\n",
    "* Faça o ``prompt do sistema`` o mais detalhado possível - dedique a maior parte do seu tempo aqui\n",
    "* A ``temperatura`` controla a aleatoriedade da próxima palavra\n",
    "    * ``0.1-0.5`` para precisão factual (codificação, documentos técnicos)\n",
    "    * ``0.5-1`` para criatividade (brainstorming (gerar ideias), menos robótico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c152cbd7",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``2.``Gerenciando conversas com um agente</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c84418",
   "metadata": {},
   "source": [
    "* A maioria dos frameworks de construção de agentes não possui memória embutida\n",
    "* Os casos de uso em produção são diferentes\n",
    "* O ``Mistral`` vem com memória embutida e gerenciamento de conversas\n",
    "\n",
    "<font color=\"red\">``I.`` Iniciando uma nova conversa</font>\n",
    "\n",
    "* O comando ``start`` sempre espera um novo ID de agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d10c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui estão três melhores práticas para codificar variáveis categóricas em aprendizado de máquina:\n",
      "\n",
      "1. **One-Hot Encoding**:\n",
      "   - **Descrição**: Transforma cada categoria em uma coluna binária (0 ou 1). Cada coluna representa uma categoria única.\n",
      "   - **Quando usar**: Quando as categorias não têm uma ordem intrínseca (por exemplo, cores, países).\n",
      "   - **Exemplo**: Se você tem uma variável \"Cor\" com categorias \"Vermelho\", \"Azul\" e \"Verde\", o One-Hot Encoding criará três colunas binárias, cada uma representando uma dessas cores.\n",
      "\n",
      "2. **Label Encoding**:\n",
      "   - **Descrição**: Atribui um número inteiro único a cada categoria.\n",
      "   - **Quando usar**: Quando as categorias têm uma ordem intrínseca (por exemplo, níveis de educação: \"Ensino Fundamental\", \"Ensino Médio\", \"Ensino Superior\").\n",
      "   - **Exemplo**: Se você tem uma variável \"Nível de Educação\" com categorias \"Ensino Fundamental\", \"Ensino Médio\" e \"Ensino Superior\", o Label Encoding pode atribuir 0, 1 e 2, respectivamente.\n",
      "\n",
      "3. **Embedding**:\n",
      "   - **Descrição**: Usa redes neurais para transformar categorias em vetores de números reais em um espaço de menor dimensão.\n",
      "   - **Quando usar**: Quando você tem um grande número de categorias e deseja capturar relações complexas entre elas, geralmente em modelos de deep learning.\n",
      "   - **Exemplo**: Em processamento de linguagem natural, palavras são frequentemente transformadas em embeddings para capturar semelhanças semânticas.\n",
      "\n",
      "Essas técnicas ajudam a transformar variáveis categóricas em formatos que podem ser processados por algoritmos de aprendizado de máquina.\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.conversations.start(\n",
    "    agent_id=ml_agent.id,\n",
    "    inputs=\"\"\"Quais são as melhores práticas para codificar variáveis \n",
    "              categóricas em aprendizado de máquina? Liste três.\"\"\",\n",
    ")\n",
    "\n",
    "print(response.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729393d",
   "metadata": {},
   "source": [
    "* Todos os objetos de ``response`` de conversação também têm um ``ID``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab120234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_01981929efd671908fe477e0bc9cf15c\n"
     ]
    }
   ],
   "source": [
    "print(response.conversation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76259a0",
   "metadata": {},
   "source": [
    "<font color=\"red\">``II.`` Continuando uma conversa existente</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ff3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sua primeira pergunta foi: \"Quais são as melhores práticas para codificar variáveis categóricas em aprendizado de máquina? Liste três.\"\n"
     ]
    }
   ],
   "source": [
    "# Continuar uma conversa existente:\n",
    "follow_up = client.beta.conversations.append(\n",
    "    conversation_id=response.conversation_id,\n",
    "    inputs=\"Qual foi a minha primeira pergunta?\",\n",
    ")\n",
    "\n",
    "print(follow_up.outputs[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974d6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você perguntou sobre as melhores práticas para codificar variáveis categóricas em aprendizado de máquina. Eu listei três técnicas: One-Hot Encoding, Label Encoding e Embedding. Em seguida, você perguntou qual foi a sua primeira pergunta.\n"
     ]
    }
   ],
   "source": [
    "follow_up = client.beta.conversations.append(\n",
    "    conversation_id=response.conversation_id,\n",
    "    inputs=\"Resuma toda a conversa em 3 frases.\",\n",
    ")\n",
    "\n",
    "print(follow_up.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7257a4",
   "metadata": {},
   "source": [
    "<font color=\"red\">``III.`` Listando todas as conversas</font>\n",
    "\n",
    "* Para gerenciamento interno, você pode ver todas as conversas dos agentes rapidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e76a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_list = client.beta.conversations.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c217470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "012b96e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv_01981929efd671908fe477e0bc9cf15c'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_list[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f7297e",
   "metadata": {},
   "source": [
    "* As conversas mais recentes vêm primeiro nesta lista.\n",
    "* Você pode obter o histórico completo de mensagens com ``get_messages``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a4b6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageInputEntry(role='user', content='Quais são as melhores práticas para codificar variáveis \\n              categóricas em aprendizado de máquina? Liste três.', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 16, 13, 55, 541356, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_01981929efd5774395e0ea813cc7f090', prefix=False),\n",
       " MessageOutputEntry(content='Aqui estão três melhores práticas para codificar variáveis categóricas em aprendizado de máquina:\\n\\n1. **One-Hot Encoding**:\\n   - **Descrição**: Transforma cada categoria em uma coluna binária (0 ou 1). Cada coluna representa uma categoria única.\\n   - **Quando usar**: Quando as categorias não têm uma ordem intrínseca (por exemplo, cores, países).\\n   - **Exemplo**: Se você tem uma variável \"Cor\" com categorias \"Vermelho\", \"Azul\" e \"Verde\", o One-Hot Encoding criará três colunas binárias, cada uma representando uma dessas cores.\\n\\n2. **Label Encoding**:\\n   - **Descrição**: Atribui um número inteiro único a cada categoria.\\n   - **Quando usar**: Quando as categorias têm uma ordem intrínseca (por exemplo, níveis de educação: \"Ensino Fundamental\", \"Ensino Médio\", \"Ensino Superior\").\\n   - **Exemplo**: Se você tem uma variável \"Nível de Educação\" com categorias \"Ensino Fundamental\", \"Ensino Médio\" e \"Ensino Superior\", o Label Encoding pode atribuir 0, 1 e 2, respectivamente.\\n\\n3. **Embedding**:\\n   - **Descrição**: Usa redes neurais para transformar categorias em vetores de números reais em um espaço de menor dimensão.\\n   - **Quando usar**: Quando você tem um grande número de categorias e deseja capturar relações complexas entre elas, geralmente em modelos de deep learning.\\n   - **Exemplo**: Em processamento de linguagem natural, palavras são frequentemente transformadas em embeddings para capturar semelhanças semânticas.\\n\\nEssas técnicas ajudam a transformar variáveis categóricas em formatos que podem ser processados por algoritmos de aprendizado de máquina.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 16, 13, 55, 671813, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_01981929f0577332b4851a543ecc9174', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant'),\n",
       " MessageInputEntry(role='user', content='Qual foi a minha primeira pergunta?', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 17, 59, 40, 524933, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198ac0ec749c9b5943bd43a3b82f', prefix=False),\n",
       " MessageOutputEntry(content='Sua primeira pergunta foi: \"Quais são as melhores práticas para codificar variáveis categóricas em aprendizado de máquina? Liste três.\"', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 17, 59, 40, 723863, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198ac1b37641a4ef7d318a2bbfec', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant'),\n",
       " MessageInputEntry(role='user', content='Resuma toda a conversa em 3 frases.', object='entry', type='message.input', created_at=datetime.datetime(2025, 7, 17, 18, 0, 24, 348626, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198b6c1c739795074bdb6ec9b4d3', prefix=False),\n",
       " MessageOutputEntry(content='Você perguntou sobre as melhores práticas para codificar variáveis categóricas em aprendizado de máquina. Eu listei três técnicas: One-Hot Encoding, Label Encoding e Embedding. Em seguida, você perguntou qual foi a sua primeira pergunta.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 18, 0, 24, 551025, tzinfo=TzInfo(UTC)), completed_at=None, id='msg_0198198b6ce6716c8421d1ba70e45087', agent_id='ag_019818e32a1c73d88638d1a73a709ff8', model='mistral-medium-2505', role='assistant')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = client.beta.conversations.get_messages(conversation_id=conversations_list[0].id)\n",
    "\n",
    "conversation.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b068aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversation.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60074c0d",
   "metadata": {},
   "source": [
    "* Importante ao construir aplicativos de chat (bate-papo) com histórico de mensagens\n",
    "* Veja outros [métodos de gerenciamento de conversa](https://docs.mistral.ai/agents/agents_basics/#conversations) na documentação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d15415",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``3.`` Respostas de streaming para facilidade de uso</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c38b0",
   "metadata": {},
   "source": [
    "* Os agentes devem ser amigáveis.\n",
    "* Transmita respostas sem fazê-los esperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5cbc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Explique a descida do gradiente em termos simples em 2 frases.\"\n",
    "\n",
    "response = client.beta.conversations.start_stream(\n",
    "    agent_id=ml_agent.id, inputs=message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a903655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistralai.utils.eventstreaming.EventStream"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b70cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mistralai.utils.eventstreaming.EventStream object at 0x7f5e942f3770>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8b8ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A descida do gradiente é como descer uma montanha aos poucos, sempre escolhendo o caminho mais íngreme para baixo. Em machine learning, usamos essa técnica para ajustar os parâmetros do modelo de forma a minimizar o erro, ou seja, encontrar o melhor \"vale\" que representa a solução ótima."
     ]
    }
   ],
   "source": [
    "# Usando o stream de eventos:\n",
    "with response as event_stream:\n",
    "    for event in event_stream:\n",
    "        # Verifique o tipo de evento:\n",
    "        if event.event == \"message.output.delta\":\n",
    "            print(event.data.content, flush=True, end=\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8a7c9",
   "metadata": {},
   "source": [
    "* ``start_stream`` cria uma nova conversa como ``conversations.start``\n",
    "* ``append_stream`` continua essa conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58756566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La bajada de gradiente es como bajar una montaña poco a poco, siempre eligiendo el camino más empinado hacia abajo. En el aprendizaje automático, usamos esta técnica para ajustar los parámetros del modelo con el fin de minimizar el error, es decir, encontrar el mejor \"valle\" que representa la solución óptima."
     ]
    }
   ],
   "source": [
    "# Obter o ID da última conversa para continuar:\n",
    "last_conversation_id = client.beta.conversations.list()[0].id\n",
    "\n",
    "message = \"Traduza sua última resposta para o Espanhol.\"\n",
    "follow_up = client.beta.conversations.append_stream(\n",
    "    conversation_id=last_conversation_id, inputs=message\n",
    ")\n",
    "\n",
    "with follow_up as event_stream:\n",
    "    for event in event_stream:\n",
    "        if event.event == \"message.output.delta\":\n",
    "            print(event.data.content, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb051a6",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``4.`` Usando a pesquisa na web para obter informações em tempo real</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf3ee",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.mistral.ai/img/websearch_connector.png\" width=\"400\" alt=\"Diagrama de conexão para pesquisa web\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6121638a",
   "metadata": {},
   "source": [
    "* A maioria dos LLMs vive em 2024.\n",
    "* Têm alucinações quando questionados sobre os eventos de 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bcdc45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-latest\",\n",
    "    name=\"ml-research-agent\",\n",
    "    description=\"Especialista em pesquisa de Machine Learning (ML)\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    ")\n",
    "\n",
    "search_response = client.beta.conversations.start(\n",
    "    agent_id=research_agent.id, inputs=\"Resumo das últimas melhorias em Transformer em 2025\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2c2c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolExecutionEntry(name='web_search', arguments='{\"query\": \"Resumo das últimas melhorias em Transformer em 2025\"}', object='entry', type='tool.execution', created_at=datetime.datetime(2025, 7, 17, 19, 8, 23, 371202, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 19, 8, 24, 723588, tzinfo=TzInfo(UTC)), id='tool_exec_019819c9a9cb71528b028a6cab5c42c0', info={}), MessageOutputEntry(content=[TextChunk(text='Em 2025, as melhorias nos modelos Transformer continuaram a avançar significativamente, impulsionando ainda mais a capacidade e a eficiência desses modelos em diversas aplicações de inteligência artificial. Aqui estão algumas das principais melhorias e tendências observadas:  \\n  \\n1. **Eficiência Computacional**:  \\n   - Os modelos Transformer estão se tornando mais eficientes em termos computacionais. Novas técnicas de compressão de modelos e otimização de hardware permitem que esses modelos sejam executados em dispositivos com menos recursos, como smartphones e dispositivos IoT, sem sacrificar significativamente o desempenho', type='text'), ToolReferenceChunk(tool='web_search', title='Arquitetura transformers: O que é, Como Funciona e Benefícios | MOD', type='tool_reference', url='https://mercadoonlinedigital.com/blog/transformers/', favicon='https://imgs.search.brave.com/dQYtVZHFYeV-X5QHMrfmO35kuZEZuCm0xq0eyIkS8pw/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMDBlYzYzNmY4/OWZmZGNhMzZmZjIx/ODIzOGQwYWYyZmE4/NTEzZjFmNThmYWE0/NjdmNDVhN2ZmNTVm/OWFkM2VkYi9tZXJj/YWRvb25saW5lZGln/aXRhbC5jb20v', description='Descubra a revolução da arquitetura <strong>transformers</strong>, uma abordagem inovadora que está por trás dos avanços da inteligência artificial. Confira!'), TextChunk(text='.  \\n  \\n2. **Avanços em Multimodalidade**:  \\n   - A integração de dados multimodais (texto, imagem, áudio) em um único modelo Transformer tem visto avanços significativos. Modelos como o CLIP (Contrastive Language–Image Pretraining) e DALL-E estão sendo aprimorados para entender e gerar conteúdo multimodal de maneira mais coerente e contextualizada. Isso permite aplicações mais robustas em áreas como geração de arte, análise de mídia social e assistentes virtuais mais inteligentes', type='text'), ToolReferenceChunk(tool='web_search', title='What are Transformers? - Transformers in Artificial Intelligence Explained - AWS', type='tool_reference', url='https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/', favicon='https://imgs.search.brave.com/w1pARvp0PsgKW9VIQkl3hv9-fqD3BFvfwsgJeUDHdUQ/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvOWFkODM4NDk0/MTRjNzUyMTM3OTQ5/MmI4MjRkZjFhNDcw/MTIxYzI3NmZmMmNm/MDFkZWRjNmFkZjYz/NzVhZmIzMC9hd3Mu/YW1hem9uLmNvbS8', description='What is <strong>Transformers</strong> in Artificial Intelligence how and why businesses use <strong>Transformers</strong> in Artificial Intelligence, and how to use <strong>Transformers</strong> in Artificial Intelligence <strong>with</strong> AWS.'), TextChunk(text='.  \\n  \\n3. **Melhorias em Atenção e Memória**:  \\n   - Novas variantes da camada de atenção, como a atenção esparsa e a atenção baseada em memória, estão sendo desenvolvidas para melhorar a eficiência e a capacidade dos modelos Transformer. Essas inovações permitem que os modelos lidem melhor com sequências mais longas e complexas, melhorando a precisão em tarefas como tradução automática e sumarização de textos longos', type='text'), ToolReferenceChunk(tool='web_search', title='How Transformers Work: A Detailed Exploration of Transformer Architecture | DataCamp', type='tool_reference', url='https://www.datacamp.com/tutorial/how-transformers-work', favicon='https://imgs.search.brave.com/YV5sojK5QsZJNk2w2tHrpkx2YgkvmS-p5nbsTHpqfyY/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvZmM4ODRiMTE0/NTQyY2YzZTAxZTIw/NzdmZDcwOGVmNTBh/NGFjMjRjODMzYzRm/NDIxMzY2ZmZjMTgz/YmM2ZjRkNi93d3cu/ZGF0YWNhbXAuY29t/Lw', description='Explore the architecture of <strong>Transformers</strong>, the models that have revolutionized data handling through self-attention mechanisms, surpassing traditional RNNs, and paving the way for advanced models like BERT and GPT.'), TextChunk(text='.  \\n  \\n4. **Aplicações em Saúde**:  \\n   - Os modelos Transformer estão sendo cada vez mais aplicados na área da saúde, desde a análise de prontuários médicos até a descoberta de novos medicamentos. A capacidade de processar grandes volumes de dados e identificar padrões complexos está ajudando a acelerar pesquisas e melhorar diagnósticos. Em 2025, espera-se que mais hospitais e instituições de pesquisa adotem essas tecnologias para melhorar a precisão e a velocidade dos tratamentos', type='text'), ToolReferenceChunk(tool='web_search', title='O que é um Modelo Transformer? | Blog da NVIDIA', type='tool_reference', url='https://blog.nvidia.com.br/blog/o-que-e-um-modelo-transformer/', favicon='https://imgs.search.brave.com/-pLUhXxADnywJ5lntDhoMIWqmbPAxnzYAVgfpN8A9EU/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvZjQ3ZmNmMDdi/Mjc1NmU5MzQ0ZDIw/OTkzMWQ0M2M0NzNl/YzExZjE4MGFiMDM0/N2FkNDE0YWRiOGI3/MGVlN2ZiMS9ibG9n/Lm52aWRpYS5jb20u/YnIv', description='<strong>Os transformers podem detectar tendências e anomalias para evitar fraudes, simplificar a manufatura, fazer recomendações on-line ou melhorar a área da saúde</strong>. As pessoas usam transformers toda vez que pesquisam no Google ou no Microsoft Bing. Qualquer aplicação que use dados sequenciais ...'), TextChunk(text='.  \\n  \\n5. **Personalização e Adaptabilidade**:  \\n   - Os modelos Transformer estão se tornando mais adaptáveis a contextos específicos e personalizáveis para usuários individuais. Isso é particularmente útil em aplicações como assistentes pessoais, onde o modelo pode aprender e adaptar-se às preferências e necessidades específicas de um usuário ao longo do tempo.  \\n  \\n6. **Avanços em Processamento de Linguagem Natural (PLN)**:  \\n   - A compreensão contextual e a geração de linguagem natural continuam a melhorar. Modelos como o GPT-5 estão sendo treinados com conjuntos de dados ainda maiores e mais diversos, permitindo uma compreensão mais profunda e uma geração de texto mais coerente e contextualmente apropriada. Isso está levando a avanços em áreas como chatbots, tradução automática e análise de sentimentos', type='text'), ToolReferenceChunk(tool='web_search', title='O que é um GPT? Introdução aos Transformers na Inteligência Artificial', type='tool_reference', url='https://www.guilhermefavaron.com.br/post/transformers-inteligencia-artificial', favicon='https://imgs.search.brave.com/qbpt0klx8-_C_3Z8NZqRO2RcaexUemRYH7itxHJ5ifo/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMDc4MjFiYWVm/NzU4ZGZlYTczODNm/NjI5ZTM0ZDdmNjll/YTQ5MzkwNDI5MTNk/OGU1MTRjYzIyYzBi/NjBlNTcwNC93d3cu/Z3VpbGhlcm1lZmF2/YXJvbi5jb20uYnIv', description='Explore como os <strong>Transformers</strong> estão redefinindo os limites da Inteligência Artificial, desde o processamento de linguagem natural até aplicações inovadoras <strong>em</strong> diversas áreas. Descubra o funcionamento, o impacto e o futuro desta revolucionária arquitetura de IA neste guia completo.'), TextChunk(text='.  \\n  \\n7. **Integração com Outras Tecnologias**:  \\n   - Os modelos Transformer estão sendo integrados com outras tecnologias emergentes, como blockchain e computação quântica, para criar sistemas ainda mais poderosos e seguros. Essa integração está abrindo novas possibilidades em áreas como segurança cibernética e análise de dados em tempo real.  \\n  \\nEssas melhorias estão posicionando os modelos Transformer como uma das tecnologias mais influentes e transformadoras na área de inteligência artificial, com aplicações que se estendem por quase todos os setores da economia e da sociedade.', type='text')], object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 19, 8, 25, 453840, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 19, 8, 39, 906444, tzinfo=TzInfo(UTC)), id='msg_019819c9b1ed75cf925aeb94e2635f76', agent_id='ag_019819c99cad72219bf14205d85dcdc8', model='mistral-medium-latest', role='assistant')]\n"
     ]
    }
   ],
   "source": [
    "print(search_response.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633fe446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextChunk(text='Em 2025, as melhorias nos modelos Transformer continuaram a avançar significativamente, impulsionando ainda mais a capacidade e a eficiência desses modelos em diversas aplicações de inteligência artificial. Aqui estão algumas das principais melhorias e tendências observadas:  \\n  \\n1. **Eficiência Computacional**:  \\n   - Os modelos Transformer estão se tornando mais eficientes em termos computacionais. Novas técnicas de compressão de modelos e otimização de hardware permitem que esses modelos sejam executados em dispositivos com menos recursos, como smartphones e dispositivos IoT, sem sacrificar significativamente o desempenho', type='text'),\n",
       " ToolReferenceChunk(tool='web_search', title='Arquitetura transformers: O que é, Como Funciona e Benefícios | MOD', type='tool_reference', url='https://mercadoonlinedigital.com/blog/transformers/', favicon='https://imgs.search.brave.com/dQYtVZHFYeV-X5QHMrfmO35kuZEZuCm0xq0eyIkS8pw/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMDBlYzYzNmY4/OWZmZGNhMzZmZjIx/ODIzOGQwYWYyZmE4/NTEzZjFmNThmYWE0/NjdmNDVhN2ZmNTVm/OWFkM2VkYi9tZXJj/YWRvb25saW5lZGln/aXRhbC5jb20v', description='Descubra a revolução da arquitetura <strong>transformers</strong>, uma abordagem inovadora que está por trás dos avanços da inteligência artificial. Confira!'),\n",
       " TextChunk(text='.  \\n  \\n2. **Avanços em Multimodalidade**:  \\n   - A integração de dados multimodais (texto, imagem, áudio) em um único modelo Transformer tem visto avanços significativos. Modelos como o CLIP (Contrastive Language–Image Pretraining) e DALL-E estão sendo aprimorados para entender e gerar conteúdo multimodal de maneira mais coerente e contextualizada. Isso permite aplicações mais robustas em áreas como geração de arte, análise de mídia social e assistentes virtuais mais inteligentes', type='text'),\n",
       " ToolReferenceChunk(tool='web_search', title='What are Transformers? - Transformers in Artificial Intelligence Explained - AWS', type='tool_reference', url='https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/', favicon='https://imgs.search.brave.com/w1pARvp0PsgKW9VIQkl3hv9-fqD3BFvfwsgJeUDHdUQ/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvOWFkODM4NDk0/MTRjNzUyMTM3OTQ5/MmI4MjRkZjFhNDcw/MTIxYzI3NmZmMmNm/MDFkZWRjNmFkZjYz/NzVhZmIzMC9hd3Mu/YW1hem9uLmNvbS8', description='What is <strong>Transformers</strong> in Artificial Intelligence how and why businesses use <strong>Transformers</strong> in Artificial Intelligence, and how to use <strong>Transformers</strong> in Artificial Intelligence <strong>with</strong> AWS.'),\n",
       " TextChunk(text='.  \\n  \\n3. **Melhorias em Atenção e Memória**:  \\n   - Novas variantes da camada de atenção, como a atenção esparsa e a atenção baseada em memória, estão sendo desenvolvidas para melhorar a eficiência e a capacidade dos modelos Transformer. Essas inovações permitem que os modelos lidem melhor com sequências mais longas e complexas, melhorando a precisão em tarefas como tradução automática e sumarização de textos longos', type='text'),\n",
       " ToolReferenceChunk(tool='web_search', title='How Transformers Work: A Detailed Exploration of Transformer Architecture | DataCamp', type='tool_reference', url='https://www.datacamp.com/tutorial/how-transformers-work', favicon='https://imgs.search.brave.com/YV5sojK5QsZJNk2w2tHrpkx2YgkvmS-p5nbsTHpqfyY/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvZmM4ODRiMTE0/NTQyY2YzZTAxZTIw/NzdmZDcwOGVmNTBh/NGFjMjRjODMzYzRm/NDIxMzY2ZmZjMTgz/YmM2ZjRkNi93d3cu/ZGF0YWNhbXAuY29t/Lw', description='Explore the architecture of <strong>Transformers</strong>, the models that have revolutionized data handling through self-attention mechanisms, surpassing traditional RNNs, and paving the way for advanced models like BERT and GPT.'),\n",
       " TextChunk(text='.  \\n  \\n4. **Aplicações em Saúde**:  \\n   - Os modelos Transformer estão sendo cada vez mais aplicados na área da saúde, desde a análise de prontuários médicos até a descoberta de novos medicamentos. A capacidade de processar grandes volumes de dados e identificar padrões complexos está ajudando a acelerar pesquisas e melhorar diagnósticos. Em 2025, espera-se que mais hospitais e instituições de pesquisa adotem essas tecnologias para melhorar a precisão e a velocidade dos tratamentos', type='text'),\n",
       " ToolReferenceChunk(tool='web_search', title='O que é um Modelo Transformer? | Blog da NVIDIA', type='tool_reference', url='https://blog.nvidia.com.br/blog/o-que-e-um-modelo-transformer/', favicon='https://imgs.search.brave.com/-pLUhXxADnywJ5lntDhoMIWqmbPAxnzYAVgfpN8A9EU/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvZjQ3ZmNmMDdi/Mjc1NmU5MzQ0ZDIw/OTkzMWQ0M2M0NzNl/YzExZjE4MGFiMDM0/N2FkNDE0YWRiOGI3/MGVlN2ZiMS9ibG9n/Lm52aWRpYS5jb20u/YnIv', description='<strong>Os transformers podem detectar tendências e anomalias para evitar fraudes, simplificar a manufatura, fazer recomendações on-line ou melhorar a área da saúde</strong>. As pessoas usam transformers toda vez que pesquisam no Google ou no Microsoft Bing. Qualquer aplicação que use dados sequenciais ...'),\n",
       " TextChunk(text='.  \\n  \\n5. **Personalização e Adaptabilidade**:  \\n   - Os modelos Transformer estão se tornando mais adaptáveis a contextos específicos e personalizáveis para usuários individuais. Isso é particularmente útil em aplicações como assistentes pessoais, onde o modelo pode aprender e adaptar-se às preferências e necessidades específicas de um usuário ao longo do tempo.  \\n  \\n6. **Avanços em Processamento de Linguagem Natural (PLN)**:  \\n   - A compreensão contextual e a geração de linguagem natural continuam a melhorar. Modelos como o GPT-5 estão sendo treinados com conjuntos de dados ainda maiores e mais diversos, permitindo uma compreensão mais profunda e uma geração de texto mais coerente e contextualmente apropriada. Isso está levando a avanços em áreas como chatbots, tradução automática e análise de sentimentos', type='text'),\n",
       " ToolReferenceChunk(tool='web_search', title='O que é um GPT? Introdução aos Transformers na Inteligência Artificial', type='tool_reference', url='https://www.guilhermefavaron.com.br/post/transformers-inteligencia-artificial', favicon='https://imgs.search.brave.com/qbpt0klx8-_C_3Z8NZqRO2RcaexUemRYH7itxHJ5ifo/rs:fit:32:32:1:0/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMDc4MjFiYWVm/NzU4ZGZlYTczODNm/NjI5ZTM0ZDdmNjll/YTQ5MzkwNDI5MTNk/OGU1MTRjYzIyYzBi/NjBlNTcwNC93d3cu/Z3VpbGhlcm1lZmF2/YXJvbi5jb20uYnIv', description='Explore como os <strong>Transformers</strong> estão redefinindo os limites da Inteligência Artificial, desde o processamento de linguagem natural até aplicações inovadoras <strong>em</strong> diversas áreas. Descubra o funcionamento, o impacto e o futuro desta revolucionária arquitetura de IA neste guia completo.'),\n",
       " TextChunk(text='.  \\n  \\n7. **Integração com Outras Tecnologias**:  \\n   - Os modelos Transformer estão sendo integrados com outras tecnologias emergentes, como blockchain e computação quântica, para criar sistemas ainda mais poderosos e seguros. Essa integração está abrindo novas possibilidades em áreas como segurança cibernética e análise de dados em tempo real.  \\n  \\nEssas melhorias estão posicionando os modelos Transformer como uma das tecnologias mais influentes e transformadoras na área de inteligência artificial, com aplicações que se estendem por quase todos os setores da economia e da sociedade.', type='text')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_response.outputs[1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d144c",
   "metadata": {},
   "source": [
    "* ``web_search`` retorna texto com citações.\n",
    "* Isso requer formatação especial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "115337cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\n",
    "\n",
    "for result in search_response.outputs[1].content:\n",
    "    if hasattr(result, \"text\"):\n",
    "        markdown_text += result.text\n",
    "    if hasattr(result, \"tool\"):\n",
    "        markdown_text += f\" ([{result.title}]({result.url}))\"  # Links are given []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3032f87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Em 2025, as melhorias nos modelos Transformer continuaram a avançar significativamente, impulsionando ainda mais a capacidade e a eficiência desses modelos em diversas aplicações de inteligência artificial. Aqui estão algumas das principais melhorias e tendências observadas:  \n",
       "  \n",
       "1. **Eficiência Computacional**:  \n",
       "   - Os modelos Transformer estão se tornando mais eficientes em termos computacionais. Novas técnicas de compressão de modelos e otimização de hardware permitem que esses modelos sejam executados em dispositivos com menos recursos, como smartphones e dispositivos IoT, sem sacrificar significativamente o desempenho ([Arquitetura transformers: O que é, Como Funciona e Benefícios | MOD](https://mercadoonlinedigital.com/blog/transformers/)).  \n",
       "  \n",
       "2. **Avanços em Multimodalidade**:  \n",
       "   - A integração de dados multimodais (texto, imagem, áudio) em um único modelo Transformer tem visto avanços significativos. Modelos como o CLIP (Contrastive Language–Image Pretraining) e DALL-E estão sendo aprimorados para entender e gerar conteúdo multimodal de maneira mais coerente e contextualizada. Isso permite aplicações mais robustas em áreas como geração de arte, análise de mídia social e assistentes virtuais mais inteligentes ([What are Transformers? - Transformers in Artificial Intelligence Explained - AWS](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/)).  \n",
       "  \n",
       "3. **Melhorias em Atenção e Memória**:  \n",
       "   - Novas variantes da camada de atenção, como a atenção esparsa e a atenção baseada em memória, estão sendo desenvolvidas para melhorar a eficiência e a capacidade dos modelos Transformer. Essas inovações permitem que os modelos lidem melhor com sequências mais longas e complexas, melhorando a precisão em tarefas como tradução automática e sumarização de textos longos ([How Transformers Work: A Detailed Exploration of Transformer Architecture | DataCamp](https://www.datacamp.com/tutorial/how-transformers-work)).  \n",
       "  \n",
       "4. **Aplicações em Saúde**:  \n",
       "   - Os modelos Transformer estão sendo cada vez mais aplicados na área da saúde, desde a análise de prontuários médicos até a descoberta de novos medicamentos. A capacidade de processar grandes volumes de dados e identificar padrões complexos está ajudando a acelerar pesquisas e melhorar diagnósticos. Em 2025, espera-se que mais hospitais e instituições de pesquisa adotem essas tecnologias para melhorar a precisão e a velocidade dos tratamentos ([O que é um Modelo Transformer? | Blog da NVIDIA](https://blog.nvidia.com.br/blog/o-que-e-um-modelo-transformer/)).  \n",
       "  \n",
       "5. **Personalização e Adaptabilidade**:  \n",
       "   - Os modelos Transformer estão se tornando mais adaptáveis a contextos específicos e personalizáveis para usuários individuais. Isso é particularmente útil em aplicações como assistentes pessoais, onde o modelo pode aprender e adaptar-se às preferências e necessidades específicas de um usuário ao longo do tempo.  \n",
       "  \n",
       "6. **Avanços em Processamento de Linguagem Natural (PLN)**:  \n",
       "   - A compreensão contextual e a geração de linguagem natural continuam a melhorar. Modelos como o GPT-5 estão sendo treinados com conjuntos de dados ainda maiores e mais diversos, permitindo uma compreensão mais profunda e uma geração de texto mais coerente e contextualmente apropriada. Isso está levando a avanços em áreas como chatbots, tradução automática e análise de sentimentos ([O que é um GPT? Introdução aos Transformers na Inteligência Artificial](https://www.guilhermefavaron.com.br/post/transformers-inteligencia-artificial)).  \n",
       "  \n",
       "7. **Integração com Outras Tecnologias**:  \n",
       "   - Os modelos Transformer estão sendo integrados com outras tecnologias emergentes, como blockchain e computação quântica, para criar sistemas ainda mais poderosos e seguros. Essa integração está abrindo novas possibilidades em áreas como segurança cibernética e análise de dados em tempo real.  \n",
       "  \n",
       "Essas melhorias estão posicionando os modelos Transformer como uma das tecnologias mais influentes e transformadoras na área de inteligência artificial, com aplicações que se estendem por quase todos os setores da economia e da sociedade."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "764a315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuar a conversa após os resultados:\n",
    "follow_up = client.beta.conversations.append(\n",
    "    conversation_id=search_response.conversation_id,\n",
    "    inputs=\"Resuma os resultados em 2 frases.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7d273c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em 2025, os modelos Transformer continuaram a evoluir com melhorias significativas em eficiência computacional, capacidades multimodais e aplicações em saúde, tornando-se mais adaptáveis e integrados com outras tecnologias emergentes. Esses avanços estão expandindo suas aplicações em diversas áreas, desde assistentes pessoais até descoberta de medicamentos, consolidando sua posição como uma das tecnologias mais influentes em inteligência artificial.\n"
     ]
    }
   ],
   "source": [
    "print(follow_up.outputs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a803d",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">``5.`` Usando execução de código para tarefas complexas</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e725480",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.mistral.ai/img/code_interpreter_connector.png\" width=\"400\" alt=\"Diagrama de conexão do Code Interpreter\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aab1c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_agent = client.beta.agents.create(\n",
    "    model=\"mistral-medium-2505\",\n",
    "    name=\"coding-assistant\",\n",
    "    description=\"Especialista em execução de código\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n",
    "\n",
    "message = \"\"\"Resolva e visualize a equação do conjunto de Mandelbrot z = z² + c. \n",
    "            Calcule a convergência para uma grade de plano complexo, crie uma \n",
    "            bela arte de parede fractal com mapeamento de cores personalizado.\"\"\"\n",
    "\n",
    "code_response = client.beta.conversations.start(\n",
    "    agent_id=code_agent.id,\n",
    "    inputs=message,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f6bb96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageOutputEntry(content='Para resolver e visualizar o conjunto de Mandelbrot, precisamos iterar sobre uma grade de números complexos e determinar se a sequência \\\\( z = z^2 + c \\\\) converge ou diverge. Podemos então mapear os resultados para criar uma visualização colorida do fractal.\\n\\nVamos prosseguir com o código para gerar essa visualização.', object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 19, 23, 19, 269715, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 19, 23, 20, 682289, tzinfo=TzInfo(UTC)), id='msg_019819d75565703e8d4493e1fdc47bee', agent_id='ag_019819d75039708580e582f29546ad0d', model='mistral-medium-2505', role='assistant'),\n",
       " ToolExecutionEntry(name='code_interpreter', arguments='{\"code\": \"import numpy as np\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Definindo a função do conjunto de Mandelbrot\\\\ndef mandelbrot(c, max_iter):\\\\n    z = c\\\\n    for n in range(max_iter):\\\\n        if abs(z) > 2:\\\\n            return n\\\\n        z = z*z + c\\\\n    return max_iter\\\\n\\\\n# Configurações da grade e iterações\\\\nxmin, xmax = -2.0, 1.0\\\\nymin, ymax = -1.5, 1.5\\\\nwidth, height = 800, 800\\\\nmax_iter = 256\\\\n\\\\n# Criando a grade de números complexos\\\\nx = np.linspace(xmin, xmax, width)\\\\ny = np.linspace(ymin, ymax, height)\\\\nX, Y = np.meshgrid(x, y)\\\\nC = X + 1j * Y\\\\n\\\\n# Calculando o conjunto de Mandelbrot\\\\nmandelbrot_set = np.array([[mandelbrot(c, max_iter) for c in row] for row in C])\\\\n\\\\n# Visualização com mapeamento de cores personalizado\\\\nplt.figure(figsize=(10, 10))\\\\nplt.imshow(mandelbrot_set, extent=(xmin, xmax, ymin, ymax), cmap=\\'twilight_shifted\\', interpolation=\\'bilinear\\')\\\\nplt.colorbar(label=\\'Iteração em que |z| > 2\\')\\\\nplt.title(\\'Conjunto de Mandelbrot\\')\\\\nplt.xlabel(\\'Re(c)\\')\\\\nplt.ylabel(\\'Im(c)\\')\\\\nplt.show()\"}', object='entry', type='tool.execution', created_at=datetime.datetime(2025, 7, 17, 19, 23, 20, 783974, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 19, 23, 34, 481007, tzinfo=TzInfo(UTC)), id='tool_exec_019819d75b4f767a90af49659a9b387b', info={'code': \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Definindo a função do conjunto de Mandelbrot\\ndef mandelbrot(c, max_iter):\\n    z = c\\n    for n in range(max_iter):\\n        if abs(z) > 2:\\n            return n\\n        z = z*z + c\\n    return max_iter\\n\\n# Configurações da grade e iterações\\nxmin, xmax = -2.0, 1.0\\nymin, ymax = -1.5, 1.5\\nwidth, height = 800, 800\\nmax_iter = 256\\n\\n# Criando a grade de números complexos\\nx = np.linspace(xmin, xmax, width)\\ny = np.linspace(ymin, ymax, height)\\nX, Y = np.meshgrid(x, y)\\nC = X + 1j * Y\\n\\n# Calculando o conjunto de Mandelbrot\\nmandelbrot_set = np.array([[mandelbrot(c, max_iter) for c in row] for row in C])\\n\\n# Visualização com mapeamento de cores personalizado\\nplt.figure(figsize=(10, 10))\\nplt.imshow(mandelbrot_set, extent=(xmin, xmax, ymin, ymax), cmap='twilight_shifted', interpolation='bilinear')\\nplt.colorbar(label='Iteração em que |z| > 2')\\nplt.title('Conjunto de Mandelbrot')\\nplt.xlabel('Re(c)')\\nplt.ylabel('Im(c)')\\nplt.show()\", 'code_output': '<Figure size 1000x1000 with 2 Axes>\\n'}),\n",
       " MessageOutputEntry(content=[ToolFileChunk(tool='code_interpreter', file_id='d7780444-8745-43e9-9723-eaa6bd730607', type='tool_file', file_name='plot_0.png', file_type='png'), TextChunk(text='Aqui está a visualização do conjunto de Mandelbrot, uma famosa representação fractal. Cada ponto no plano complexo é colorido com base no número de iterações necessárias para que a sequência \\\\( z = z^2 + c \\\\) escape de um círculo de raio 2, ou seja, diverja. Pontos dentro do conjunto são tipicamente representados em preto, enquanto pontos fora são coloridos de acordo com a velocidade de sua divergência.\\n\\nEsta imagem pode ser usada como uma bela arte de parede fractal. Se precisar de mais alguma coisa, estou à disposição!', type='text')], object='entry', type='message.output', created_at=datetime.datetime(2025, 7, 17, 19, 23, 34, 670595, tzinfo=TzInfo(UTC)), completed_at=datetime.datetime(2025, 7, 17, 19, 23, 36, 849335, tzinfo=TzInfo(UTC)), id='msg_019819d7918e7077834966319fc40980', agent_id='ag_019819d75039708580e582f29546ad0d', model='mistral-medium-2505', role='assistant')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_response.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20b8983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='code_interpreter' arguments='{\"code\": \"import numpy as np\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Definindo a função do conjunto de Mandelbrot\\\\ndef mandelbrot(c, max_iter):\\\\n    z = c\\\\n    for n in range(max_iter):\\\\n        if abs(z) > 2:\\\\n            return n\\\\n        z = z*z + c\\\\n    return max_iter\\\\n\\\\n# Configurações da grade e iterações\\\\nxmin, xmax = -2.0, 1.0\\\\nymin, ymax = -1.5, 1.5\\\\nwidth, height = 800, 800\\\\nmax_iter = 256\\\\n\\\\n# Criando a grade de números complexos\\\\nx = np.linspace(xmin, xmax, width)\\\\ny = np.linspace(ymin, ymax, height)\\\\nX, Y = np.meshgrid(x, y)\\\\nC = X + 1j * Y\\\\n\\\\n# Calculando o conjunto de Mandelbrot\\\\nmandelbrot_set = np.array([[mandelbrot(c, max_iter) for c in row] for row in C])\\\\n\\\\n# Visualização com mapeamento de cores personalizado\\\\nplt.figure(figsize=(10, 10))\\\\nplt.imshow(mandelbrot_set, extent=(xmin, xmax, ymin, ymax), cmap=\\'twilight_shifted\\', interpolation=\\'bilinear\\')\\\\nplt.colorbar(label=\\'Iteração em que |z| > 2\\')\\\\nplt.title(\\'Conjunto de Mandelbrot\\')\\\\nplt.xlabel(\\'Re(c)\\')\\\\nplt.ylabel(\\'Im(c)\\')\\\\nplt.show()\"}' object='entry' type='tool.execution' created_at=datetime.datetime(2025, 7, 17, 19, 23, 20, 783974, tzinfo=TzInfo(UTC)) completed_at=datetime.datetime(2025, 7, 17, 19, 23, 34, 481007, tzinfo=TzInfo(UTC)) id='tool_exec_019819d75b4f767a90af49659a9b387b' info={'code': \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Definindo a função do conjunto de Mandelbrot\\ndef mandelbrot(c, max_iter):\\n    z = c\\n    for n in range(max_iter):\\n        if abs(z) > 2:\\n            return n\\n        z = z*z + c\\n    return max_iter\\n\\n# Configurações da grade e iterações\\nxmin, xmax = -2.0, 1.0\\nymin, ymax = -1.5, 1.5\\nwidth, height = 800, 800\\nmax_iter = 256\\n\\n# Criando a grade de números complexos\\nx = np.linspace(xmin, xmax, width)\\ny = np.linspace(ymin, ymax, height)\\nX, Y = np.meshgrid(x, y)\\nC = X + 1j * Y\\n\\n# Calculando o conjunto de Mandelbrot\\nmandelbrot_set = np.array([[mandelbrot(c, max_iter) for c in row] for row in C])\\n\\n# Visualização com mapeamento de cores personalizado\\nplt.figure(figsize=(10, 10))\\nplt.imshow(mandelbrot_set, extent=(xmin, xmax, ymin, ymax), cmap='twilight_shifted', interpolation='bilinear')\\nplt.colorbar(label='Iteração em que |z| > 2')\\nplt.title('Conjunto de Mandelbrot')\\nplt.xlabel('Re(c)')\\nplt.ylabel('Im(c)')\\nplt.show()\", 'code_output': '<Figure size 1000x1000 with 2 Axes>\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(code_response.outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee93053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Definindo a função do conjunto de Mandelbrot\n",
      "def mandelbrot(c, max_iter):\n",
      "    z = c\n",
      "    for n in range(max_iter):\n",
      "        if abs(z) > 2:\n",
      "            return n\n",
      "        z = z*z + c\n",
      "    return max_iter\n",
      "\n",
      "# Configurações da grade e iterações\n",
      "xmin, xmax = -2.0, 1.0\n",
      "ymin, ymax = -1.5, 1.5\n",
      "width, height = 800, 800\n",
      "max_iter = 256\n",
      "\n",
      "# Criando a grade de números complexos\n",
      "x = np.linspace(xmin, xmax, width)\n",
      "y = np.linspace(ymin, ymax, height)\n",
      "X, Y = np.meshgrid(x, y)\n",
      "C = X + 1j * Y\n",
      "\n",
      "# Calculando o conjunto de Mandelbrot\n",
      "mandelbrot_set = np.array([[mandelbrot(c, max_iter) for c in row] for row in C])\n",
      "\n",
      "# Visualização com mapeamento de cores personalizado\n",
      "plt.figure(figsize=(10, 10))\n",
      "plt.imshow(mandelbrot_set, extent=(xmin, xmax, ymin, ymax), cmap='twilight_shifted', interpolation='bilinear')\n",
      "plt.colorbar(label='Iteração em que |z| > 2')\n",
      "plt.title('Conjunto de Mandelbrot')\n",
      "plt.xlabel('Re(c)')\n",
      "plt.ylabel('Im(c)')\n",
      "plt.show()\n"
     ]
    }
   ],
   "source": [
    "code_snippet = code_response.outputs[1].info[\"code\"]\n",
    "\n",
    "print(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9debf7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolFileChunk(tool='code_interpreter', file_id='d7780444-8745-43e9-9723-eaa6bd730607', type='tool_file', file_name='plot_0.png', file_type='png')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_chunk = code_response.outputs[2].content[0]\n",
    "\n",
    "file_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbcedffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = file_chunk.file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d813245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bytes = client.files.download(file_id=file_id).read()\n",
    "\n",
    "with open(\"mandelbrot.png\", \"wb\") as f:\n",
    "    f.write(file_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756ac9f",
   "metadata": {},
   "source": [
    "# Conclusão e próximos passos\n",
    "\n",
    "* Confira a [documentação](https://mistral.ai/news/agents-api)\n",
    "\n",
    "* Explore outras ferramentas como [document search](https://docs.mistral.ai/agents/connectors/document_library/) e [image generation](https://docs.mistral.ai/agents/connectors/image_generation/)\n",
    "\n",
    "* Aprenda como usar [function calling](https://docs.mistral.ai/agents/function_calling/)\n",
    "\n",
    "* Construa [sistemas de multi-agentes](https://docs.mistral.ai/agents/handoffs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
